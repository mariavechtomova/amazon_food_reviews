{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## New examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Title</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td><img src=../data/blue_rock_candy.jpg/></td>\n",
       "      <td>Blue Raspberry Rock Candy Crystals (1 Pound Bag)</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "      <td>candy chocolate</td>\n",
       "      <td>Good product. Too good. The reason two stars are missing from my rating is because I sold an ounce to a guy named Tat and now he won't leave me alone. He shows up outside my apartment, at my school, and even when I'm out with my family. He's always begging me for \"the good stuff.\" Seeing how often I'm having to re-up, I think I'll try to cut a deal with the Superior Nut Company for wholesale shipments. They can ship it to me through the Greeks down at the docks.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td><img src=../data/toothpicks.jpg/></td>\n",
       "      <td>Cinnamon toothpicks</td>\n",
       "      <td>health personal care</td>\n",
       "      <td>personal care</td>\n",
       "      <td>WoW! Are these good and hot! That's OK because I like hot foods, peppers, etc. I am dieting and when I get hungry I get one of these. They will burn your tongue if you leave it on your tongue long. I love them and would highly recommend these over anything\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td><img src=../data/shower_gel.jpg/></td>\n",
       "      <td>Magno shower gel 700 ml</td>\n",
       "      <td>beauty</td>\n",
       "      <td>bath body</td>\n",
       "      <td>I have been using this product along with the soap for years and always come back to it. If you love bath and shower gels, and enjoy an occasional bubble bath, then MAGNO is for you. It's fragrance is like no other and it's great on the skin. I've not used bath soap in years - only MAGNO\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image, HTML\n",
    "\n",
    "images = list(map(lambda x: '<img src='+str(x)+'/>',list(reversed(glob.glob('../data/*.jpg')))))\n",
    "text = list(map(lambda x: open(x,'r').read(), glob.glob('../data/*.txt')))\n",
    "title = ['Blue Raspberry Rock Candy Crystals (1 Pound Bag)',\n",
    "                            'Cinnamon toothpicks',\n",
    "                            'Magno shower gel 700 ml']\n",
    "\n",
    "df = pd.DataFrame({'Image': images,\n",
    "                   'Title': title,\n",
    "                   'Cat1':['grocery gourmet food','health personal care','beauty'],\n",
    "                   'Cat2':['candy chocolate','personal care','bath body'],\n",
    "                   'Text': text}).reindex_axis(['Image','Title','Cat1','Cat2','Text'], axis=1)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's transform the sentences so that predictions can be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('../data/prepared_data.pickle', 'rb') as data:\n",
    "    data_dic = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab = data_dic['full_df']['vocab']\n",
    "train = data_dic['full_df']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_words(strg, vocab=vocab):\n",
    "    line = strg.split()\n",
    "    line = [\"rareword\" if x not in vocab.keys() else x for x in line]\n",
    "    result = ' '.join(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good product. Too good. The reason two stars are missing from my rating is because I sold an ounce to a guy named Tat and now he won\\'t leave me alone. He shows up outside my apartment, at my school, and even when I\\'m out with my family. He\\'s always begging me for \"the good stuff.\" Seeing how often I\\'m having to re-up, I think I\\'ll try to cut a deal with the Superior Nut Company for wholesale shipments. They can ship it to me through the Greeks down at the docks.\\n',\n",
       " \"WoW! Are these good and hot! That's OK because I like hot foods, peppers, etc. I am dieting and when I get hungry I get one of these. They will burn your tongue if you leave it on your tongue long. I love them and would highly recommend these over anything\\n\",\n",
       " \"I have been using this product along with the soap for years and always come back to it. If you love bath and shower gels, and enjoy an occasional bubble bath, then MAGNO is for you. It's fragrance is like no other and it's great on the skin. I've not used bath soap in years - only MAGNO\\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_input = list(map(replace_words,list(map(cleanData,text))))\n",
    "cleaned_input1 = [add_placeholders(x,100) if len(x.split())<=100 else ' '.join(x.split()[0:100]) for x in cleaned_input]\n",
    "final = np.array([create_sentence_vectors(x, vocab) for x in cleaned_input1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "own_text = ['I love its pine scent in the morning. I would stay hours under the running water',\n",
    "           'Thomas loves playing with this new ball. It keeps him busy when he is alone',\n",
    "           'This is awesome stuff for my summer bbq in the garden! All my friends love it!']\n",
    "\n",
    "own_cleaned_input = list(map(replace_words,list(map(cleanData,own_text))))\n",
    "own_cleaned_input1 = [add_placeholders(x,100) if len(x.split())<=100 else ' '.join(x.split()[0:100]) for x in own_cleaned_input]\n",
    "own_final = np.array([create_sentence_vectors(x, vocab) for x in own_cleaned_input1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = np.concatenate((final,own_final),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100\n",
    "BATCH_SIZE = final.shape[0]\n",
    "\n",
    "NUM_LABELS_1 = 6\n",
    "NUM_LABELS_2 = 64\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_SIZE = 128\n",
    "\n",
    "FILTER_SIZE_1 = 3\n",
    "FILTER_SIZE_2 = 4\n",
    "FILTER_SIZE_3 = 5\n",
    "NUM_FILTERS = 128\n",
    "\n",
    "## Important to set it to 1! Otherwise model will give every time different prediction\n",
    "keep_prob = 1.0\n",
    "l2_reg_lambda=0.001\n",
    "\n",
    "\n",
    "tf_test_dataset = tf.placeholder(tf.int32, shape=(BATCH_SIZE, SEQ_LENGTH))\n",
    "\n",
    "\n",
    "# Keeping track of l2 regularization loss (optional)\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "## Embedding layer\n",
    "\n",
    "embed_weigths = tf.Variable(tf.random_uniform([VOCAB_SIZE, EMBED_SIZE], -1.0, 1.0))\n",
    "    \n",
    "## Convolutional layers\n",
    "## Change to True if run again\n",
    "with tf.variable_scope(\"vars\", reuse = None):\n",
    "    \n",
    "    conv1_weights = tf.get_variable(\"conv1_w\", shape=[FILTER_SIZE_1, EMBED_SIZE, 1, NUM_FILTERS],\\\n",
    "                                                    initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    conv1_biases = tf.Variable(tf.constant(0.1, shape=[NUM_FILTERS]), name = \"conv1_b\")\n",
    "\n",
    "    conv2_weights = tf.get_variable(\"conv2_w\", shape=[FILTER_SIZE_2, EMBED_SIZE, 1, NUM_FILTERS],\\\n",
    "                                                    initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    conv2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_FILTERS]), name = \"conv2_b\")\n",
    "\n",
    "    conv3_weights = tf.get_variable(\"conv3_w\", shape=[FILTER_SIZE_3, EMBED_SIZE, 1, NUM_FILTERS],\\\n",
    "                                                    initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    conv3_biases = tf.Variable(tf.constant(0.1, shape=[NUM_FILTERS]), name = \"conv3_b\")\n",
    "\n",
    "## Fully connected layer\n",
    "\n",
    "    fc1_weights = tf.get_variable(\"fc1_w\", shape=[3*NUM_FILTERS, NUM_LABELS_1],\\\n",
    "                                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc1_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS_1]), name = \"fc1_b\")\n",
    "    \n",
    "    fc2_weights = tf.get_variable(\"fc2_w\", shape=[3*NUM_FILTERS, NUM_LABELS_2],\\\n",
    "                                                initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS_2]), name = \"fc2_b\")\n",
    "\n",
    "\n",
    "# Model:\n",
    "def model(data, keep_prob = keep_prob): \n",
    "    \n",
    "    ## Embedding layer\n",
    "    ## input shape:[BATCH_SIZE, SEQ_LENGTH]\n",
    "    ## output shape: [BATCH_SIZE, SEQ_LENGTH, EMBED_SIZE, 1]\n",
    "    \n",
    "    with tf.device('/cpu:0'), tf.name_scope(\"word2vec_embedding\"):    \n",
    "        embed_chars = tf.nn.embedding_lookup(embed_weigths, data)\n",
    "        embed_chars = tf.expand_dims(embed_chars, -1)\n",
    "    \n",
    "    ## Conv1+ReLu+max pooling\n",
    "    ## input shape: [BATCH_SIZE, SEQ_LENGTH, EMBED_SIZE, 1]\n",
    "    ## output shape: [BATCH_SIZE, 1, 1, NUM_FILTERS]\n",
    "    \n",
    "    with tf.name_scope(\"conv1-maxpool-3\"):\n",
    "        conv1 = tf.nn.conv2d(embed_chars, conv1_weights, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "        pool1 = tf.nn.max_pool(relu1, ksize=[1, SEQ_LENGTH-FILTER_SIZE_1+1, 1, 1],\n",
    "                               strides=[1, 1, 1, 1], padding='VALID')\n",
    "    ## Conv2+ReLu+max pooling\n",
    "    ## input shape: [BATCH_SIZE, SEQ_LENGTH, EMBED_SIZE, 1]\n",
    "    ## output shape: [BATCH_SIZE, 1, 1, NUM_FILTERS]\n",
    "    \n",
    "    with tf.name_scope(\"conv2-maxpool-4\"):\n",
    "        conv2 = tf.nn.conv2d(embed_chars, conv2_weights, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "        pool2 = tf.nn.max_pool(relu2, ksize=[1, SEQ_LENGTH-FILTER_SIZE_2+1, 1, 1],\n",
    "                               strides=[1, 1, 1, 1], padding='VALID')\n",
    "    \n",
    "    ## Conv3+ReLu+max pooling\n",
    "    ## input shape: [BATCH_SIZE, SEQ_LENGTH, EMBED_SIZE, 1]\n",
    "    ## output shape: [BATCH_SIZE, 1, 1, NUM_FILTERS]\n",
    "    \n",
    "    with tf.name_scope(\"conv3-maxpool-5\"):\n",
    "        conv3 = tf.nn.conv2d(embed_chars, conv3_weights, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "        relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))\n",
    "        pool3 = tf.nn.max_pool(relu3, ksize=[1, SEQ_LENGTH-FILTER_SIZE_3+1, 1, 1],\n",
    "                               strides=[1, 1, 1, 1], padding='VALID')\n",
    "    \n",
    "    ## Combine pooled features + flatten\n",
    "    ## input shape: [BATCH_SIZE, 1, 1, NUM_FILTERS]\n",
    "    ## output shape: [BATCH_SIZE, 3, 1, 1, NUM_FILTERS]\n",
    "    \n",
    "    with tf.name_scope(\"combine_flatten\"):\n",
    "        pooled_outputs = [pool1, pool2, pool3]\n",
    "        h_pool = tf.concat(pooled_outputs,3)\n",
    "        h_pool_flat = tf.reshape(h_pool, [-1, NUM_FILTERS*3])\n",
    "    \n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        h_pool_flat = tf.nn.dropout(h_pool_flat, keep_prob)\n",
    "    \n",
    "    ## Fully connected layer\n",
    "    with tf.name_scope(\"output\"):\n",
    "        return tf.matmul(h_pool_flat, fc1_weights) + fc1_biases,\\\n",
    "               tf.matmul(h_pool_flat, fc2_weights) + fc2_biases\n",
    "  \n",
    "\n",
    "logits_1, logits_2 = model(tf_test_dataset)\n",
    "\n",
    "test_prediction =  [tf.nn.softmax(model(tf_test_dataset)[0]),\\\n",
    "                    tf.nn.softmax(model(tf_test_dataset)[1])]\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/cat2_cnn_advanced.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, \"../models/cat2_cnn_advanced.ckpt\")\n",
    "    test_prediction = session.run(test_prediction,\n",
    "                                  feed_dict={tf_test_dataset : final,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Were the predictions good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1_num</th>\n",
       "      <th>cat1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1322085</th>\n",
       "      <td>0</td>\n",
       "      <td>baby products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672469</th>\n",
       "      <td>1</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40233</th>\n",
       "      <td>2</td>\n",
       "      <td>grocery  gourmet food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998811</th>\n",
       "      <td>3</td>\n",
       "      <td>health  personal care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218329</th>\n",
       "      <td>4</td>\n",
       "      <td>pet supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448659</th>\n",
       "      <td>5</td>\n",
       "      <td>toys  games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat1_num                    cat1\n",
       "1322085  0          baby products        \n",
       "672469   1          beauty               \n",
       "40233    2          grocery  gourmet food\n",
       "998811   3          health  personal care\n",
       "218329   4          pet supplies         \n",
       "448659   5          toys  games          "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1_df = train[[\"cat1_num\",\"cat1\"]].drop_duplicates().sort_values(by=\"cat1_num\")\n",
    "cat1_dict = dict(zip(cat1_df.cat1_num,cat1_df.cat1))\n",
    "\n",
    "cat1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat2_num</th>\n",
       "      <th>cat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364078</th>\n",
       "      <td>0</td>\n",
       "      <td>action  toy figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350549</th>\n",
       "      <td>1</td>\n",
       "      <td>arts  crafts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173258</th>\n",
       "      <td>2</td>\n",
       "      <td>baby  child care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300981</th>\n",
       "      <td>3</td>\n",
       "      <td>baby  toddler toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14809</th>\n",
       "      <td>4</td>\n",
       "      <td>baby food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705071</th>\n",
       "      <td>5</td>\n",
       "      <td>bath  body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142460</th>\n",
       "      <td>6</td>\n",
       "      <td>bathing  skin care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63840</th>\n",
       "      <td>7</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144693</th>\n",
       "      <td>8</td>\n",
       "      <td>birds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>9</td>\n",
       "      <td>breads  bakery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53500</th>\n",
       "      <td>10</td>\n",
       "      <td>breakfast foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374762</th>\n",
       "      <td>11</td>\n",
       "      <td>building toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210022</th>\n",
       "      <td>12</td>\n",
       "      <td>bunny rabbit central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27728</th>\n",
       "      <td>13</td>\n",
       "      <td>candy chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246082</th>\n",
       "      <td>14</td>\n",
       "      <td>car seats  accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169768</th>\n",
       "      <td>15</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47934</th>\n",
       "      <td>16</td>\n",
       "      <td>cooking  baking supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101820</th>\n",
       "      <td>17</td>\n",
       "      <td>dairy  eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231116</th>\n",
       "      <td>18</td>\n",
       "      <td>diapering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218329</th>\n",
       "      <td>19</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443255</th>\n",
       "      <td>20</td>\n",
       "      <td>dolls  accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447523</th>\n",
       "      <td>21</td>\n",
       "      <td>dress up  pretend play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609584</th>\n",
       "      <td>22</td>\n",
       "      <td>electronics for kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301200</th>\n",
       "      <td>23</td>\n",
       "      <td>feeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230999</th>\n",
       "      <td>24</td>\n",
       "      <td>fish  aquatic pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627263</th>\n",
       "      <td>25</td>\n",
       "      <td>fragrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52232</th>\n",
       "      <td>26</td>\n",
       "      <td>fresh flowers  live indoor plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376073</th>\n",
       "      <td>27</td>\n",
       "      <td>games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281988</th>\n",
       "      <td>28</td>\n",
       "      <td>gear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312461</th>\n",
       "      <td>29</td>\n",
       "      <td>gifts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902421</th>\n",
       "      <td>34</td>\n",
       "      <td>health care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34467</th>\n",
       "      <td>35</td>\n",
       "      <td>herbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599346</th>\n",
       "      <td>36</td>\n",
       "      <td>hobbies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894804</th>\n",
       "      <td>37</td>\n",
       "      <td>household supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452227</th>\n",
       "      <td>38</td>\n",
       "      <td>learning  education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664451</th>\n",
       "      <td>39</td>\n",
       "      <td>makeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59816</th>\n",
       "      <td>40</td>\n",
       "      <td>meat  poultry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45374</th>\n",
       "      <td>41</td>\n",
       "      <td>meat  seafood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149605</th>\n",
       "      <td>42</td>\n",
       "      <td>medical supplies  equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448659</th>\n",
       "      <td>43</td>\n",
       "      <td>novelty  gag toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326052</th>\n",
       "      <td>44</td>\n",
       "      <td>nursery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998811</th>\n",
       "      <td>45</td>\n",
       "      <td>nutrition  wellness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40233</th>\n",
       "      <td>46</td>\n",
       "      <td>pantry staples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049853</th>\n",
       "      <td>47</td>\n",
       "      <td>personal care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287974</th>\n",
       "      <td>48</td>\n",
       "      <td>potty training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267713</th>\n",
       "      <td>49</td>\n",
       "      <td>pregnancy  maternity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>50</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518550</th>\n",
       "      <td>51</td>\n",
       "      <td>puzzles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219384</th>\n",
       "      <td>52</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22541</th>\n",
       "      <td>53</td>\n",
       "      <td>sauces  dips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139736</th>\n",
       "      <td>54</td>\n",
       "      <td>sexual wellness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631675</th>\n",
       "      <td>55</td>\n",
       "      <td>skin care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259029</th>\n",
       "      <td>56</td>\n",
       "      <td>small animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81745</th>\n",
       "      <td>57</td>\n",
       "      <td>snack food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403902</th>\n",
       "      <td>58</td>\n",
       "      <td>sports  outdoor play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322085</th>\n",
       "      <td>59</td>\n",
       "      <td>strollers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586905</th>\n",
       "      <td>60</td>\n",
       "      <td>stuffed animals  plush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636274</th>\n",
       "      <td>61</td>\n",
       "      <td>tools  accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540234</th>\n",
       "      <td>62</td>\n",
       "      <td>tricycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597062</th>\n",
       "      <td>63</td>\n",
       "      <td>vehicles  remote control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cat2_num                               cat2\n",
       "364078   0         action  toy figures              \n",
       "350549   1         arts  crafts                     \n",
       "1173258  2         baby  child care                 \n",
       "300981   3         baby  toddler toys               \n",
       "14809    4         baby food                        \n",
       "705071   5         bath  body                       \n",
       "1142460  6         bathing  skin care               \n",
       "63840    7         beverages                        \n",
       "144693   8         birds                            \n",
       "89183    9         breads  bakery                   \n",
       "53500    10        breakfast foods                  \n",
       "374762   11        building toys                    \n",
       "210022   12        bunny rabbit central             \n",
       "27728    13        candy chocolate                  \n",
       "1246082  14        car seats  accessories           \n",
       "169768   15        cats                             \n",
       "47934    16        cooking  baking supplies         \n",
       "101820   17        dairy  eggs                      \n",
       "1231116  18        diapering                        \n",
       "218329   19        dogs                             \n",
       "443255   20        dolls  accessories               \n",
       "447523   21        dress up  pretend play           \n",
       "609584   22        electronics for kids             \n",
       "1301200  23        feeding                          \n",
       "230999   24        fish  aquatic pets               \n",
       "627263   25        fragrance                        \n",
       "52232    26        fresh flowers  live indoor plants\n",
       "376073   27        games                            \n",
       "1281988  28        gear                             \n",
       "1312461  29        gifts                            \n",
       "...      ..          ...                            \n",
       "902421   34        health care                      \n",
       "34467    35        herbs                            \n",
       "599346   36        hobbies                          \n",
       "894804   37        household supplies               \n",
       "452227   38        learning  education              \n",
       "664451   39        makeup                           \n",
       "59816    40        meat  poultry                    \n",
       "45374    41        meat  seafood                    \n",
       "1149605  42        medical supplies  equipment      \n",
       "448659   43        novelty  gag toys                \n",
       "1326052  44        nursery                          \n",
       "998811   45        nutrition  wellness              \n",
       "40233    46        pantry staples                   \n",
       "1049853  47        personal care                    \n",
       "1287974  48        potty training                   \n",
       "1267713  49        pregnancy  maternity             \n",
       "4619     50        produce                          \n",
       "518550   51        puzzles                          \n",
       "1219384  52        safety                           \n",
       "22541    53        sauces  dips                     \n",
       "1139736  54        sexual wellness                  \n",
       "631675   55        skin care                        \n",
       "259029   56        small animals                    \n",
       "81745    57        snack food                       \n",
       "403902   58        sports  outdoor play             \n",
       "1322085  59        strollers                        \n",
       "586905   60        stuffed animals  plush           \n",
       "636274   61        tools  accessories               \n",
       "540234   62        tricycles                        \n",
       "597062   63        vehicles  remote control         \n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2_df = train[[\"cat2_num\",\"cat2\"]].drop_duplicates().sort_values(by=\"cat2_num\")\n",
    "cat2_dict = dict(zip(cat2_df.cat2_num,cat2_df.cat2))\n",
    "\n",
    "cat2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category 1 for product Blue Raspberry Rock Candy Crystals (1 Pound Bag) is 2 ( grocery  gourmet food)\n",
      "Predicted category 2 for product Blue Raspberry Rock Candy Crystals (1 Pound Bag) is 45 (nutrition  wellness)\n",
      "Predicted category 1 for product Cinnamon toothpicks is 3 ( health  personal care)\n",
      "Predicted category 2 for product Cinnamon toothpicks is 34 (health care)\n",
      "Predicted category 1 for product Magno shower gel 700 ml is 1 ( beauty)\n",
      "Predicted category 2 for product Magno shower gel 700 ml is 5 (bath  body)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(title)):\n",
    "    print('Predicted category 1 for product %s is %.0f (%s)' %(title[i],\n",
    "                                                               np.argmax(test_prediction[0],1)[i],\n",
    "                                                               cat1_dict.get(np.argmax(test_prediction[0],1)[i])))\n",
    "    \n",
    "    print('Predicted category 2 for product %s is %.0f (%s)' %(title[i],\n",
    "                                                               np.argmax(test_prediction[1],1)[i],\n",
    "                                                               cat2_dict.get(np.argmax(test_prediction[1],1)[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category 1 for product \n",
      " \t I love its pine scent in the morning. I would stay hours under the running water \n",
      " is 1 ( beauty)\n",
      "Predicted category 2 for product \n",
      " \t I love its pine scent in the morning. I would stay hours under the running water \n",
      " is 25 (fragrance)\n",
      "Predicted category 1 for product \n",
      " \t Thomas loves playing with this new ball. It keeps him busy when he is alone \n",
      " is 4 ( pet supplies)\n",
      "Predicted category 2 for product \n",
      " \t Thomas loves playing with this new ball. It keeps him busy when he is alone \n",
      " is 19 (dogs)\n",
      "Predicted category 1 for product \n",
      " \t This is awesome stuff for my summer bbq in the garden! All my friends love it! \n",
      " is 5 ( toys  games)\n",
      "Predicted category 2 for product \n",
      " \t This is awesome stuff for my summer bbq in the garden! All my friends love it! \n",
      " is 25 (fragrance)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(own_text)):\n",
    "    print('Predicted category 1 for product \\n \\t %s \\n is %.0f (%s)' %(own_text[i],\n",
    "                                                               np.argmax(test_prediction[0],1)[i+3],\n",
    "                                                               cat1_dict.get(np.argmax(test_prediction[0],1)[i+3])))\n",
    "    \n",
    "    print('Predicted category 2 for product \\n \\t %s \\n is %.0f (%s)' %(own_text[i],\n",
    "                                                               np.argmax(test_prediction[1],1)[i+3],\n",
    "                                                               cat2_dict.get(np.argmax(test_prediction[1],1)[i+3])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
